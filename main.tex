% !TEX program = pdflatex
%
% Template for RBIE papers in LaTeX
%

%TODO: adicionar limitação nos dados: muitas pessoas escondem as descobertas em empresas ao invés de registrar patentes.

% The above language combination is for this template document only.
% You should use one of the following:
\documentclass[english, spanish, brazilian]{RBIEarticle} % follow the original template ordering
%\documentclass[brazilian, spanish, english]{RBIEarticle} % for papers in english
%\documentclass[brazilian, english, spanish]{RBIEarticle} % for papers in spanish

%\usepackage[table]{xcolor} % Permite colorir células, linhas e colunas
\usepackage{multirow}     % Permite mesclar linhas

% Papers in Portuguese or Spanish may require the following lines:
\usepackage[utf8]{inputenc} % chooses UTF-8 as the main character set
\usepackage[T1]{fontenc} % for correct syllable separation in accented words
% The next two statements are needed for the example table in this document
% (i.e. you don't necessarily need them in your own paper)
%\usepackage{colortbl}
%\definecolor{gray}{gray}{.8}
\usepackage{listings}
% Table formatting packages used by the manuscript's result tables
\usepackage{booktabs}
\usepackage{float}
\usepackage{longtable} % Ensure the longtable package is included in the preamble

% Citations and references (Biblatex)
% Use biber as backend and ensure alphabetical (name-year) sorting per template
\usepackage[style=apa,backend=biber,sorting=nyt]{biblatex}
\usepackage{csquotes}
\addbibresource{references.bib}

% Bibliography formatting to match RBIE template:
% - 12pt font for bibliography entries
% - hanging indent of 0.75 cm
% - single line spacing with 6pt extra space after each entry
\renewcommand*{\bibfont}{\normalfont\fontsize{12}{14}\selectfont}
\setlength{\bibhang}{0.75cm}
\setlength{\bibitemsep}{6pt}

% Make DOIs/URLs clickable (class already loads hyperref and defines \doi)
% and append a per-entry Google Scholar "[GS SEARCH]" link that queries the
% quoted title. We keep this implementation small and safe for biber.
\DeclareFieldFormat{gssearch}{% not used directly, kept for clarity
	\iffieldundef{title}{}{\space\href{https://scholar.google.com/scholar?q=\%22\thefield{title}\%22}{[GS SEARCH]}}%
}

% Renew the standard doi+eprint+url macro to print DOI and URL (if present).
\renewbibmacro*{doi+eprint+url}{%
	% print DOI if present (uses class' \doi command if available)
	\printfield{doi}%
	\newunit\newblock%
	% print URL if present
	\printfield{url}%
}

% Bibliography environment: ensure hanging indent and spacing per template.
% This harmonizes with the \bibfont / \bibhang / \bibitemsep settings above.
\defbibenvironment{bibliography}
	{\list{}{%
		 \setlength{\leftmargin}{\bibhang}%
		 \setlength{\itemindent}{-\leftmargin}%
		 \setlength{\itemsep}{\bibitemsep}%
		 \setlength{\parsep}{0pt}%
	}%
	\renewcommand{\makelabel}[1]{##1}%
	}
	{\endlist}
	{\item}

% Append the Google Scholar [GS SEARCH] link as the LAST element of each
% bibliography entry. Prefer an explicit `gsurl` field in the .bib (this
% allows exact links you provided). If `gsurl` is missing, fall back to a
% constructed query quoting the title.
% DISABLED: GS Search links removed per user request
% \AtEveryBibitem{%
% 	\iffieldundef{gsurl}{%
% 		% no explicit gsurl: fall back to constructing a query from the title
% 		\iffieldundef{title}{}{% title exists -> construct link
% 			\space\href{https://scholar.google.com/scholar?q=\%22\thefield{title}\%22}{[GS SEARCH]}%
% 		}%
% 	}{%
% 		% explicit gsurl present: print it (this will be the last thing)
% 		\space\href{\thefield{gsurl}}{[GS SEARCH]}%
% 	}%
% }

% Ensure abstract names work properly
\addto\captionsbrazilian{\renewcommand{\abstractname}{Resumo}}
\addto\captionsenglish{\renewcommand{\abstractname}{Abstract}}
\addto\captionsspanish{\renewcommand{\abstractname}{Resumen}}

% Ensure babel knows the local caption names at begin document (avoids warnings)
\AtBeginDocument{%
	\setlocalecaption{brazilian}{abstract}{Resumo}%
	\setlocalecaption{brazilian}{table}{Tabela}%
}

% Here goes the paper main title
\title{Identificação de tecnologias emergentes de etanol a partir de dados de patentes brasileiras usando ML}

% If the manuscript is written in English, then this element must be removed.
\titleinenglish{Identification of emerging ethanol technologies from Brazilian patent data using ML}

% If the manuscript is written in English, then this element must be removed.
%\titleinspanish{Identificación de tecnologías emergentes de etanol a partir de dados de patentes utilizando aprendizado automático.}

% Here goes the paper author information (repeat for two or more authors)
\author{%
	\parbox{8cm}{%
		Osvaldo Carvalho dos Santos Neto\\
		Escola de Artes, Ciências e Humanidades - USP\\
		ORCID: \href{https://orcid.org/0000-0000-0000-0000}{0000-0000-0000-0000}\\
		osvaldocsantos@usp.br
	}
	\parbox{8cm}{%
		Gabriel da Silva Simões\\
		Escola de Artes, Ciências e Humanidades - USP\\
		ORCID: \href{https://orcid.org/0000-0000-0000-0000}{0000-0000-0000-0000}\\
		gabriel.s.simoeslp@usp.br
	}
	\\ \\ \\
    \parbox{8cm}{%
		Luan Pereira Pinheiro\\
		Escola de Artes, Ciências e Humanidades - USP\\
		NUSP: 13672471\\
		luanpinheiro@usp.br
    }
    \parbox{8cm}{%
		Luis Felipe Pinheiro Felisberto\\
		Escola de Artes, Ciências e Humanidades - USP\\
		ORCID: \href{https://orcid.org/0000-0000-0000-0000}{0000-0000-0000-0000}\\
		luis.felipe@usp.br
    }
}

\Submission{18/Aug/2025}
\First_round_notif{18/Aug/2025}
\New_version{18/Aug/2025}
\Second_round_notif{20/Oct/2025}
\Camera_ready{20/Oct/2025}
\Edition_review{20/Oct/2025}
\Available_online{17/Nov/2025}
\Published{17/Nov/2025}

% Here goes the page heading information
\heading{Felisberto et al.}{2025}

% And finally here goes the citation information
\citeas{Neto, O. C. S., Simões, G. S., Pinheiro, L. P. \& Felisberto, L. F. P. (2025). Identificação de tecnologias emergentes de etanol a partir de dados de patentes usando ML. Revista Brasileira de Informática na Educação}

%====================================================================
%\hyphenpenalty=10000
%\setcounter{page}{01}

\begin{document}

\maketitle

% Use the original template's language blocks for abstracts so the class handles captions/spacing
\begin{otherlanguage}{brazilian}
% Ensure the abstract heading is correct in this language block
\renewcommand{\abstractname}{Resumo}
\begin{abstract}
Estudamos patentes brasileiras para identificar tecnologias emergentes de etanol usando Random Forest e SVM em fluxos semi‑supervisionado e supervisionado. Comparamos duas definições operacionais de "promissora", por citações futuras e por evolução de códigos IPC, e avaliamos estratégias de agregação de IPC e ajuste de limiar. Em termos gerais, a definição por citações favoreceu melhores resultados para o Random Forest em relação ao SVM, enquanto a definição baseada em IPC elevou de modo consistente o desempenho, especialmente quando combinada com agregação de IPC e aprendizagem semi‑supervisionada. \keywords, Etanol; Patente; Aprendizado de Máquina; Random Forest; Support Vector Machine; IPC.
\end{abstract}
\end{otherlanguage}

\begin{otherlanguage}{english}
\begin{abstract}
We study Brazilian patents to identify emerging ethanol technologies using Random Forest and SVM in semi‑supervised and supervised pipelines. We compare two operational definitions of "promising", by future citations and by IPC code evolution, and evaluate IPC aggregation and threshold‑tuning strategies. Overall, the citation‑based definition tended to favor Random Forest relative to SVM, while the IPC‑based definition consistently improved performance, particularly when combined with IPC aggregation and semi‑supervised learning. \keywords, Ethanol; Patent; Machine Learning; Random Forest; Support Vector Machine; IPC.
\end{abstract}
\end{otherlanguage}

% keep the main document language as Brazilian Portuguese
\selectlanguage{brazilian}

% Ensure localized captions are defined after the language is selected
\renewcommand{\abstractname}{Resumo}
\renewcommand{\tablename}{Tabela}

% If the manuscript is written in English, then this element must be removed.
% \begin{otherlanguage}{spanish}
% \begin{abstract}
% <Aquí viene el resumen del artículo en español. El resumen debe resumir el contenido del manuscrito y debe contener un mínimo de 150 y un máximo de 300~palabras y debe estar escrito en cursiva, Times~10, justificado, sin sangría especial e sin espaço antes ou depois.>
% \keywords <El resumen debe ir seguido de 3 a 10 palabras clave. Las palabras clave deben estar justificadas con un espacio de línea simple, sin sangría especial, sin espacios antes y con un espacio de exactamente 24 puntos después. El texto debe configurarse fuente Times con tamaño de 10 puntos y en estilo de fuente cursiva. Utilice punto y coma como separador. Las palabras clave deben comenzar con una letra mayúscula.>
% \end{abstract}
% \end{otherlanguage}

\pagebreak

%====================================================================

\section{Introdução}
O etanol, ou álcool etílico, é uma substância de grande importância na indústria em geral. No setor energético, ele se destaca como uma alternativa menos poluente e renovável comparada aos combustíveis fósseis, já que, dentre outras vantagens, emite 73\% a menos de CO2 que a gasolina \parencite{EMBRAPA2025b}. Segundo a \textcite{EMBRAPA2025c}, a indústria alcoolquímica que utiliza o etanol como matéria-prima para a fabricação de produtos poderá vir a substituir a petroquímica, colocando o álcool etílico como uma opção de matéria-prima acima do petróleo.

O Brasil é o maior produtor do mundo de cana-de-açúcar e, na safra 2020/2021, foi responsável pela produção de 654,5 milhões de toneladas, destinadas à produção de 41,2 milhões de toneladas de açúcar e 29,7 bilhões de litros de etanol \parencite{CONAB2021}. O estado de São Paulo foi o líder na produção do país, com 425,6 milhões de toneladas colhidas e 14,7 milhões m³ de etanol produzidos, segundo o \textcite{SEADE2025}.

Esses dados colocam o etanol como um produto de extrema importância para o avanço em relação aos Objetivos de Desenvolvimento Sustentável (ODS), em particular o ODS 7: energia limpa e sustentável \parencite{ONU2025}. Sendo assim, o estudo de tecnologias de etanol emergentes desenvolvidas no Brasil se faz relevante no cenário brasileiro e global, além de servir de apoio para o avanço do ODS 9 (indústria, inovação e infraestrutura), especialmente nos tópicos 9.5 e 9.b, que são detalhados a seguir \parencite{ONU2025}:
\begin{itemize}
    \item[\textbf{9.5}] Fortalecer a pesquisa científica, melhorar as capacidades tecnológicas de setores industriais em todos os países, particularmente os países em desenvolvimento, inclusive, até 2030, incentivando a inovação e aumentando substancialmente o número de trabalhadores de pesquisa e desenvolvimento por milhão de pessoas e os gastos público e privado em pesquisa e desenvolvimento.
    \item[\textbf{9.b}] Apoiar o desenvolvimento tecnológico, a pesquisa e a inovação nacionais nos países em desenvolvimento, inclusive garantindo um ambiente político propício para, entre outras coisas, diversificação industrial e agregação de valor às commodities.
\end{itemize}

\section{Fundamentos Teóricos}
Para o desenvolvimento do presente trabalho, alguns fundamentos teóricos são essenciais, tais como o conceito de patentes e conceitos relacionados aos algoritmos de aprendizado de máquina usados na identificação das tecnologias emergentes. Esses fundamentos serão apresentados nesta seção.

Patente é um título de propriedade temporária sobre uma invenção ou modelo de utilidade, outorgado pelo Estado aos inventores \parencite{SEBRAE2025}. Em 2023, o \textcite{INPI2023} registrou o depósito de 27.918 patentes, um crescimento de 2,9\% em relação ao período anterior.

Uma predição é o resultado de uma análise que permite inferir previamente conclusões sobre o futuro. Essas inferências são consideradas valiosas para a indústria na tomada de decisões, de forma a minimizar riscos e custos e a atingir os objetivos com maior segurança (LIN, 2021, p.~74, citado em \parencite[p.~5]{Lee2022}). Neste trabalho será comparado o desempenho de um algoritmo de Random Forest e de um Support Vector Machine na realização de predições assertivas.

Uma árvore de decisão é um tipo de diagrama hierárquico que ajuda a visualizar etapas, decisões e o possível resultado de cada decisão popular em machine learning para tarefas de classificação e regressão de modelos \parencite{IBM1}. Random forest é um algoritmo utilizado para tarefas de classificação e regressão que combina a saída de múltiplas árvores de decisão para alcançar um único resultado \parencite{IBM2}.

Uma máquina de vetores de suporte (SVM) é um algoritmo supervisionado de aprendizado de máquina que classifica dados encontrando uma linha ou hiperplano ótimo que maximiza a distância entre cada classe em um espaço N-dimensional \parencite{IBM3}.

A base da possibilidade de inferir quais são as tecnologias promissoras vem da implicação que a rede de patentes conectadas pelas citações se comporta de forma similar a um grafo direcionado evoluindo, cujas conexões representam referências a uma tecnologia anterior como base para criação de uma nova, logo os vértices de origem mais centrais podem ser destacados como fonte de inovação. Logo, algoritmos de aprendizado supervisionado como Random Forest e Support Vector Machine podem ser treinados a partir de dados anteriores para reconhecer e destacar as características desses vértices, de forma a obter as patentes, autores e tecnologias citadas.

Mais especificamente, neste trabalho faremos uso de algoritmos de aprendizado supervisionado e semissupervisionado. Estes últimos consistem em algoritmos que fazem uso das técnicas de aprendizado supervisionado em um pequeno conjunto de dados, como base para um aprendizado não supervisionado para um conjunto grande de dados \parencite{Zhu2005}.

\section{Trabalhos Relacionados}
No estudo de \textcite{Chung2020}, “Early detection of valuable patents using a deep learning model: Case of semiconductor industry”, é proposto um modelo de aprendizado profundo combinando CNN e LSTM para extrair características semânticas de patentes, classificando-as em três níveis de valor com base em citações futuras anuais. O modelo apresentou mais de 75\% de precisão na identificação de patentes promissoras no setor de semicondutores. 

De forma complementar, \textcite{kwon2020identification} utilizaram 17 indicadores de patentes e técnicas de machine learning para prever invenções promissoras, destacando que a qualidade da acumulação de conhecimento é o preditor mais relevante para o sucesso das invenções.

Além disso, o estudo de \textcite{hu2023evaluation} avaliou patentes de circuitos integrados por meio de uma estratégia multidimensional de indicadores e diferentes modelos de machine learning, verificando que o algoritmo Random Forest alcançou precisão e acurácia superiores a 95\% na classificação de patentes de alto valor. 

No domínio de veículos elétricos, \textcite{han2022assessing} abordaram a previsão de citações futuras como um problema de classificação, utilizando SVM otimizado para identificar patentes altamente citadas e mapear frentes tecnológicas emergentes.

Em patentes de biomedicina têxtil, \textcite{he2025patent} desenvolveram o modelo BioTexVal, integrando BERT e múltiplos algoritmos de machine learning para prever o valor das patentes, alcançando aproximadamente 88\% de acurácia ao treinar com 113.428 patentes.

No contexto brasileiro, \textcite{kazmi2025innovations} investigaram o papel do país no desenvolvimento de tecnologias para produção de etanol de segunda geração por meio da análise de patentes publicadas entre 2006 e 2015.

No estudo “Forecasting emerging technologies: A supervised learning approach through patent analysis” de \textcite{kyebambe2017forecasting} desenvolveu um algoritmo para rotular automaticamente clusters de patentes como “emergentes” ou “não emergentes” e usar esses dados para treinar modelos de aprendizado de máquina supervisionado. Nos baseamos em algumas métricas e definições vindas desse trabalho na realização da nossa pesquisa. No entanto, diferente do nosso estudo, o artigo de Kyebambe busca identificar ondas tecnológicas emergentes enquanto nós buscamos identificar uma tecnologia emergente apenas, de forma que certas adaptações foram necessárias.

Por fim, o trabalho de \textcite{choi2021identifying} apresentou uma abordagem semi-supervisionada para identificar tecnologias emergentes, combinando um pequeno conjunto de patentes rotuladas por especialistas com um grande conjunto não rotulado, permitindo rotular automaticamente muitas patentes e facilitar a descoberta de inovações promissoras. Nosso estudo se inspira principalmente nesta metodologia, buscando preencher a lacuna existente na análise de patentes recentes de tecnologias emergentes de etanol no Brasil. Entretanto, o estudo simula a rotulação dos especialistas pelas citações futuras, que é uma definição que pode ser enviesada; por isso, preferimos não utilizá-la.

\section{Metodologia}
O desenvolvimento deste estudo demandou, inicialmente, uma etapa de coleta e organização de dados. Para isso, utilizamos a base de dados da Organização Mundial da Propriedade Intelectual (WIPO).

Para assegurar comparabilidade metodológica, selecionamos os mesmos códigos IPC utilizados por \textcite{Perrone2011}, cujo foco também recai sobre tecnologias associadas à produção de etanol. Dessa forma, incorporamos uma estratégia validada previamente na literatura. Adicionalmente, diversas consultas foram testadas na WIPO até se chegar à expressão de busca final, reproduzida abaixo:

\begin{lstlisting}[breaklines=true,basicstyle=\ttfamily\small]
IC:(C12P OR C12N OR C10L OR C07C OR A23B) AND 
FP:(metanol OR methanol OR sugar OR etanol OR ethanol OR cana OR stover OR celulose OR bagasse OR madeira OR wood OR wooden OR cellulose OR bagaco OR beterraba OR beet OR sugarcane OR sucrose OR acucar* OR melaco OR melaco OR alcool* OR bioetanol OR bioethanol OR etil* OR milho OR corn OR soy OR soybean OR soja OR cereal OR trigo OR starch OR lignocellulose OR lignocelulose OR palha OR res?duo* OR biomass OR biomassa)
\end{lstlisting}

A busca retornou informações como título da patente, inventores, data e número de publicação (identificador). Realizou-se, então, um tratamento desses identificadores, visto que o identificador é específico para a base de dados, não correspondendo ao identificador global da patente.

Com os identificadores tratados (i.e. trocados pelo identificador global), desenvolveu-se um \textit{web scraper} em Python para extrair das páginas do Google Patents e da Organização de Patentes Europeias as variáveis necessárias ao treinamento dos modelos de aprendizado de máquina. Uma  As variáveis coletadas e calculadas foram:

\begin{enumerate}
    \item Número de reivindicações independentes;
    \item Número de inventores;
    \item Número de imagens da patente;
    \item Número de membros da família de patentes;
    \item Número de citações anteriores;
    \item Número de referências a não-patentes;
	\item Número de citações de não-patentes;
    \item Número de classificações IPC e CPC;
	\item Classificadores IPC e CPC da patente;
	\item Diversidade dos IPCs e CPCs.
    \item Diversidade tecnológica;
	\item Número de substantivos no título;
	\item Número de aplicações;
	\item Soma da quantidade das 10 palavras mais frequentes no título na descrição da patente;
\end{enumerate}

Usamos uma definição de patente promissora baseada na usada por \textcite{kyebambe2017forecasting}: são consideradas promissoras as patentes que possuem pelo menos um código IPC mais recente do que a própria data de publicação da patente. A premissa é que essas patentes têm maior potencial de avanço tecnológico, pois introduzem conceitos ou tecnologias que foram formalmente reconhecidos em classificações posteriores.

Para o treinamento dos modelos, utilizou-se um conjunto de patentes publicadas entre 1974 e 2015. Em cada ano, as 10\% de patentes com maior número de citações a termo foram rotuladas como “promissoras” (variável-alvo), enquanto as demais foram rotuladas como “não promissoras”. Após essa rotulação, a variável de citações a termo foi removida do conjunto de treinamento para evitar vazamento de informação.

A partir do conjunto rotulado, reservou-se 10\% para compor o conjunto de teste. Os 90\% restantes foram utilizados para o treinamento.

No caso do treinamento semissupervisionado, 30\% permaneceram como dados rotulados e 70\% foram tratados como não rotulados. Todo esse processamento foi realizado em Python utilizando a biblioteca Pandas.

Os dados rotulados e não rotulados foram usados para treinar os algoritmos Random Forest e Support Vector Machine (SVM). O Random Forest contribui para mitigar vieses decorrentes do comportamento de uma única árvore, enquanto o SVM fornece uma fronteira de decisão robusta para classificação binária. O desempenho dos modelos foi avaliado no conjunto de teste mediante as métricas AUROC, AUC e F1-Score. O F1-Score permite reduzir falsos positivos e falsos negativos, enquanto a AUROC avalia a capacidade discriminante dos modelos.

Além disso, para ambos os modelos, realizamos uma otimização do limiar de decisão (threshold) para melhorar o F1-Score. O limiar padrão de 0,5 pode não ser ideal, especialmente em conjuntos de dados desbalanceados. Desenvolvemos uma função para testar diferentes limiares e selecionar aquele que maximiza o F1-Score no conjunto de teste.

O processo semi-supervisionado foi dividido em duas etapas. Na primeira, ambos os modelos foram treinados exclusivamente com o conjunto rotulado, aplicando-se validação cruzada via GridSearchCV da biblioteca \texttt{scikit-learn}. Para o SVM, testaram-se combinações dos parâmetros \texttt{C}, \texttt{gamma}, \texttt{kernel} (mantido como \texttt{rbf}) e \texttt{class\_weight}. Os valores testados foram: 
\begin{itemize}
    \item \texttt{C}: 0.1, 1, 10, 100, 1000;
    \item \texttt{gamma}: 1, 0.1, 0.01, 0.001, 0.0001.
\end{itemize}

Para o Random Forest, os parâmetros avaliados foram:
\begin{itemize}
    \item \texttt{n\_estimators}: 100, 200, 300;
    \item \texttt{max\_depth}: 10, 20, None;
    \item \texttt{min\_samples\_leaf}: 1, 2, 4;
    \item \texttt{bootstrap}: True;
    \item \texttt{class\_weight}: balanced.
\end{itemize}

Em ambos os casos, utilizou-se \texttt{refit=True} para readequar o melhor modelo ao conjunto completo, \texttt{scoring='f1'} para otimizar o F1-Score e \texttt{cv=5} para empregar cinco \textit{k-folds}. O GridSearchCV retornou automaticamente os modelos com os melhores hiperparâmetros.

Na segunda etapa, os modelos treinados foram utilizados para classificar o conjunto não rotulado, e em seguida foram retreinados incorporando essas novas classificações.

Por fim, testamos uma estratégia de agregação de códigos IPC. A ideia é agrupar códigos IPC semelhantes em categorias mais amplas, reduzindo a granularidade dos dados e potencialmente melhorando a capacidade dos modelos de identificar padrões relevantes. Essa agregação também foi baseada em uma das métricas do \parencite{kyebambe2017forecasting}, e foi realizada com base na hierarquia dos códigos IPC, agrupando-os em níveis mais altos (seções ou classes) antes do treinamento dos modelos.

\section{Resultados e Discussão}
Ao acessar a plataforma da WIPO obtivemos um conjunto de 6242 patentes em 10 de outubro de 2025. O conjunto de patentes obtido do WIPO possui informações como número de pedido, número da submissão, data da submissão, país, título e IPC. No entanto, devido à idade de algumas patentes e à sua disponibilidade na internet, o conjunto final de patentes foi reduzido a 4973 patentes.

Realizando a separação do conjunto de dados total pelas patentes de 1974 a 2015 obtivemos o conjunto de treinamento com 4115 patentes. Deste conjunto obtivemos os valores presentes na tabela 1.

\begin{longtable}{c c c c}
\caption{Distribuição anual de patentes e proporção de patentes promissoras}\\
\toprule
\textbf{Ano} & \textbf{Promissoras} & \textbf{Não promissoras} &  \textbf{Proporção} \\
\midrule
\endfirsthead
\caption[]{Distribuição anual de patentes e proporção de patentes promissoras (continuação)}\\
\toprule
\textbf{Ano} & \textbf{Promissoras} & \textbf{Não promissoras} &  \textbf{Proporção} \\
\midrule
\endhead
\midrule
\multicolumn{4}{r}{Continua na próxima página}
\endfoot
\bottomrule
\endlastfoot
1974 & 3 & 1 & 75.00\% \\
1975 & 7 & 4 & 63.64\% \\
1976 & 13 & 4 & 76.47\% \\
1977 & 14 & 9 & 60.87\% \\
1978 & 8 & 8 & 50.00\% \\
1979 & 27 & 13 & 67.50\% \\
1980 & 19 & 41 & 31.67\% \\
1981 & 28 & 44 & 38.89\% \\
1982 & 10 & 34 & 22.73\% \\
1983 & 12 & 29 & 29.27\% \\
1984 & 12 & 25 & 32.43\% \\
1985 & 10 & 32 & 23.81\% \\
1986 & 9 & 27 & 25.00\% \\
1987 & 15 & 14 & 51.72\% \\
1988 & 15 & 20 & 42.86\% \\
1989 & 11 & 18 & 37.93\% \\
1990 & 5 & 20 & 20.00\% \\
1991 & 5 & 28 & 15.15\% \\
1992 & 3 & 19 & 13.64\% \\
1993 & 7 & 17 & 29.17\% \\
1994 & 8 & 16 & 33.33\% \\
1995 & 2 & 23 & 8.00\% \\
1996 & 10 & 46 & 17.86\% \\
1997 & 15 & 82 & 15.46\% \\
1998 & 35 & 126 & 21.74\% \\
1999 & 29 & 145 & 16.67\% \\
2000 & 16 & 154 & 9.41\% \\
2001 & 11 & 145 & 7.05\% \\
2002 & 10 & 113 & 8.13\% \\
2003 & 11 & 125 & 8.09\% \\
2004 & 2 & 26 & 7.14\% \\
2005 & 0 & 47 & 0.00\% \\
2006 & 0 & 68 & 0.00\% \\
2007 & 0 & 114 & 0.00\% \\
2008 & 4 & 140 & 2.78\% \\
2009 & 4 & 212 & 1.85\% \\
2010 & 2 & 228 & 0.87\% \\
2011 & 0 & 277 & 0.00\% \\
2012 & 0 & 356 & 0.00\% \\
2013 & 0 & 367 & 0.00\% \\
2014 & 1 & 291 & 0.34\% \\
2015 & 4 & 210 & 1.87\% \\
2016 & 0 & 161 & 0.00\% \\
2017 & 1 & 196 & 0.51\% \\
2018 & 0 & 172 & 0.00\% \\
2019 & 3 & 151 & 1.95\% \\
2020 & 0 & 268 & 0.00\% \\
2021 & 2 & 295 & 0.67\% \\
2022 & 0 & 12 & 0.00\% \\
\textbf{Total} & \textbf{403} & \textbf{4973} & \textbf{7.50\%} \\
\end{longtable}

Com isso, nós partimos para o treino supervisionado com validação cruzada. Os modelos obtiveram os valores presentes na tabela 2.

\begin{table}[H]
        \centering
        \begin{tabular}{c c c c}
                \toprule
                \textbf{Modelo} & \textbf{Melhor Limiar} & \textbf{F1-Score} & \textbf{AUROC} \\
                \midrule
                SVM                   & 0.1745  & 0.4384 & 0.8004 \\
                Random Forest & 0.2791  & \textbf{0.5814} & \textbf{0.9117} \\
        \bottomrule
        \end{tabular}
        \caption{Desempenho dos modelos SVM e Random Forest no conjunto de teste}
\end{table}

Usamos cada um dos modelo para classificar o conjunto de 2174 patentes não rotuladas e após a classificação retreinamos o SVM e o Random Forest com o conjunto total rotulado obtendo os modelos finais. Desses modelos obtivemos as seguintes métricas na tabela 3.

\begin{table}[H]
	\centering
	\begin{tabular}{c c c}
		\toprule
		\textbf{aaa} & \textbf{F1-Score} & \textbf{AUROC} \\
		\midrule
		SVM 		  & 0.3529  & 0.8538 \\
		Random Forest & 0.4923  & 0.8561 \\
	\bottomrule
	\end{tabular}
	\caption{Valores de F1-Score e AUROC dos modelos finais}
\end{table}

A partir dos dados, podemos perceber que as métricas caíram em relação aos modelos anteriores. Isso possivelmente decorre do conjunto de dados rotulado ser pequeno, o que dificulta o aprendizado do modelo. Entretanto, a métrica AUROC continua acima de 50\%, demonstrando que o modelo aprendeu a diferenciar, em alguma medida, as patentes promissoras das não promissoras. O F1-Score decaiu no modelo SVM e continua abaixo dos 50\%, o que indica que o modelo classifica patentes promissoras como não promissoras (falsos negativos) e patentes não promissoras como promissoras (falsos positivos). As matrizes de confusão nas tabelas 4 e 5 ilustram esse comportamento.

\begin{table}[H]
	\centering
	\begin{tabular}{c c c}
		\toprule
		 & \textbf{Não promissora} & \textbf{Promissora} \\
		\midrule
		Não promissora 		  & 206  & 104\% \\
		Promissora			  & 5    & 31\% \\
	\bottomrule
	\end{tabular}
	\caption{Matriz de confusão do modelo SVM}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c}
		\toprule
		 & \textbf{Não promissora} & \textbf{Promissora} \\
		\midrule
		Não promissora 		  & 297  & 13\% \\
		Promissora			  & 20   & 16\% \\
	\bottomrule
	\end{tabular}
	\caption{Matriz de confusão do modelo Random Forest}
\end{table}

Identificamos que o problema do F1-Score pode estar no limiar de decisão (threshold). Por padrão, esse limiar é 0,5 nos modelos. Assim, como a probabilidade de uma patente ser promissora é, dadas as proporções dos conjuntos, geralmente inferior a 0,5, o modelo tende a classificar muitas observações como não promissoras, gerando muitos falsos negativos.

Para resolver esse problema, buscamos encontrar um limiar de decisão mais adequado, criando uma função dedicada para otimizá-lo. Um limiar menor que 0,5 aumentou (0.3529 para 0.4528) o F1-Score do SVM, enquanto o limiar do Random Forest se manteve o mesmo, sem alterar o F1-Score. Nas tabelas abaixo podemos visualizar o desempenho dos dois modelos.

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c c}
		\toprule
		 & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support}\\
		\midrule
		Não promissora  & 0.96 & 0.85 & 0.90 & 310 \\
		Promissora	    & 0.34 & 0.67 & 0.45 & 36  \\
		&&&&\\
		accuracy & & 0.83 & & 346 \\
		macro avg       & 0.65 & 0.76 & 0.68 & 346 \\
		weighted avg    & 0.89 & 0.83 & 0.85 & 346 \\
	\bottomrule
	\end{tabular}
	\caption{Relatório de classificação do SVM}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c c}
		\toprule
		 & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support}\\
		\midrule
		Não promissora  & 0.94 & 0.96 & 0.95 & 310 \\
		Promissora	    & 0.55 & 0.44 & 0.49 & 36  \\
		&&&&\\
		accuracy & & 0.90 & & 346 \\
		macro avg       & 0.74 & 0.70 & 0.72 & 346 \\
		weighted avg    & 0.90 & 0.90 & 0.90 & 346 \\
	\bottomrule
	\end{tabular}
	\caption{Relatório de classificação do Random Forest}
\end{table}

\subsection{Experimentos com Nova Hipótese de Definição de Patente Promissora}

Nesta fase, trocamos a definição de patente promissora.

A nova rotulagem teve \textbf{397 patentes} da base de dados consideradas como promissoras. Devido a grande quantidade de patentes antigas promissoras na base, incluímos dados mais antigos no treinamento, o que resultou em um conjunto total de treinamento de \textbf{4115 patentes}, com uma proporção de $\sim$9,6\% de patentes promissoras. A Tabela 8 resume o desempenho obtido no conjunto de teste com esta nova rotulagem.

A comparação direta com os resultados iniciais do modelo final (Tabela 3) mostra uma melhora significativa nas métricase. O modelo \textbf{Random Forest} alcançou o melhor desempenho global neste cenário.

\subsubsection{Experimento de Agregação da Classificação IPC}

Foi conduzido um experimento avaliando o impacto de diferentes níveis de agregação do código IPC. Foram criadas novas variáveis que representam a quais classes, subclasses, grupos ou subgrupos as patentes estão associadas, testando a representação com \textbf{1, 2, 3 e 4 caracteres} do código IPC. A Tabela 9 resume os resultados obtidos com o \textbf{Aprendizado Semissupervisionado}.

\begin{table}[H]
        \centering
        \begin{tabular}{c c c c c}
                \toprule
                \textbf{Nível IPC} & \textbf{F1-Score SVM} & \textbf{F1-Score RF} & \textbf{AUROC SVM} & \textbf{AUROC RF} \\
                \midrule
                1	& 0.4058	& 0.6118	& 0.8581	& 0.8947 \\
                2	& 0.4865	& 0.6087	& 0.8317	& \textbf{0.9177} \\
                3	& 0.5278	& \textbf{0.6667}	& 0.8331	& 0.9176 \\
                4	& 0.4590	& 0.6154	& 0.8140	& 0.9153 \\
        \bottomrule
        \end{tabular}
        \caption{Resultados do F1-Score e AUROC para diferentes níveis de agregação de IPC (Aprendizado Semissupervisionado)}
\end{table}

O modelo \textbf{Random Forest} com agregação de \textbf{3 caracteres} do IPC alcançou o maior \textbf{F1-Score de 0.6667}, o que representa a melhor configuração para o problema em um cenário semissupervisionado.

\subsubsection{Experimento com Aprendizado Supervisionado Puro e Comparação}

Para estabelecer uma base de comparação e avaliar o desempenho em um cenário onde apenas os dados rotulados revisados são utilizados, foi executado um experimento de \textbf{Aprendizado Supervisionado Puro}. A Tabela 10 resume o desempenho desta abordagem.

\begin{table}[H]
        \centering
        \begin{tabular}{c c c c c}
                \toprule
                \textbf{Nível IPC} & \textbf{F1-Score SVM} & \textbf{F1-Score RF} & \textbf{AUROC SVM} & \textbf{AUROC RF} \\
                \midrule
                1	& 0.4124	& 0.6400	& 0.8558	& 0.9118 \\
                2	& 0.4400	& 0.6567	& 0.8103	& \textbf{0.9312} \\
                3	& 0.5000	& 0.3333	& 0.8384	& 0.9310 \\
                4	& \textbf{0.5610}	& 0.3673	& \textbf{0.8940}	& \textbf{0.9317} \\
        \bottomrule
        \end{tabular}
        \caption{Resultados do F1-Score e AUROC para diferentes níveis de agregação de IPC (Aprendizado Supervisionado Puro)}
\end{table}

Os principais insights extraídos deste experimento são:
\begin{itemize}
    \item O \textbf{Random Forest Semissupervisionado} (Nível IPC 3) obteve o pico de \textbf{F1-Score (0.6667)}. O ganho marginal nos valores calculados para o F1-Score sugere que o uso de dados não rotulados foi benéfico para essa variável.
    \item A abordagem \textbf{Supervisionada Pura} se destacou nos resultados de \textbf{AUROC}, alcançando o melhor desempenho de discriminação geral para ambos os modelos (AUROC RF de 0.9317 com Nível IPC 4), indicando uma fronteira de decisão mais estável quando treinada exclusivamente com os rótulos de alta qualidade.
\end{itemize}

Os resultados finais confirmam que a \textbf{redefinição da patente promissora}, a \textbf{agregação do IPC} e a \textbf{otimização do limiar} foram os fatores de maior impacto para o desempenho, independentemente da escolha do método de treinamento.

\section{Conclusão}
Nesta pesquisa comparamos como diferentes definições de “patente promissora” afetam os resultados e a interpretação dos modelos. Duas famílias de critérios foram testadas: (A) a definição baseada em citações futuras (rotulagem por percentil de citações — p.ex. top 10\% por ano), que busca capturar impacto futuro; e (B) a definição baseada em evolução de classificação IPC (hipótese inspirada em \textcite{kyebambe2017forecasting}), que sinaliza patentes que introduzem códigos IPC reconhecidos posteriormente (potencial de novidade tecnológica). Também testamos uma variante prática desta última que produziu 397 patentes rotuladas como promissoras e levou a ajustes no conjunto de treinamento.

	Com a definição baseada em citações (top 10\%), os modelos apresentaram AUROC consistentes ($\sim0.85$) mas F1 moderado (SVM $\sim0.3529$, RF $\sim0.4923$). Nessa configuração, o desbalanceamento e a natureza do alvo (impacto futuro) favoreceram abordagens que priorizam calibração e ordenação por pontuação (ranking), e tornaram sensível a escolha do limiar de decisão (threshold tuning melhorou o F1 do SVM).

	Com a definição baseada em evolução de IPC (experimento alternativo), observou‑se melhora substancial em ambos os modelos: o Random Forest alcançou F1 $\sim0.5814$ e AUROC $\sim0.9117$ na tabela correspondente, e, combinando agregação de IPC e semissupervisionamento, o F1 do RF chegou a $\sim0.6667$ em uma configuração ótima. Essas diferenças decorrem de mudanças na composição e no balanceamento do conjunto rotulado (nova definição rotulou 397 patentes e alterou a janela temporal dos exemplos usados no treino).

Foram limitações do nosso trabalho: (a) a limitação do conjunto de dados de patentes, que só incluiu patentes aplicadas até 2022, o que impede a identificação de patentes atualmente emergentes; (b) a ausência de validação da rotulagem por especialistas humanos; e (c) a falta de análise detalhada das características das patentes classificadas como promissoras. Trabalhos futuros podem explorar essas questões, além de investigar outras técnicas de aprendizado. Além disso, a inconclusividade da comparação entre aprendizado supervisionado puro e semissupervisionado sugere que mais experimentos são necessários para entender melhor o impacto do uso de dados não rotulados.
\printbibliography

\end{document}

